{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.1429 Acc: 0.6606\n",
      "test Loss: 0.2871 Acc: 0.9160\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.2072 Acc: 0.9367\n",
      "test Loss: 0.1326 Acc: 0.9599\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9616\n",
      "test Loss: 0.1102 Acc: 0.9657\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.0972 Acc: 0.9714\n",
      "test Loss: 0.0768 Acc: 0.9768\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.0820 Acc: 0.9746\n",
      "test Loss: 0.0695 Acc: 0.9783\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.0717 Acc: 0.9785\n",
      "test Loss: 0.0587 Acc: 0.9807\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.0639 Acc: 0.9810\n",
      "test Loss: 0.0556 Acc: 0.9826\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.0577 Acc: 0.9822\n",
      "test Loss: 0.0528 Acc: 0.9839\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0526 Acc: 0.9840\n",
      "test Loss: 0.0457 Acc: 0.9859\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0490 Acc: 0.9848\n",
      "test Loss: 0.0467 Acc: 0.9850\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0456 Acc: 0.9860\n",
      "test Loss: 0.0424 Acc: 0.9862\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0426 Acc: 0.9869\n",
      "test Loss: 0.0465 Acc: 0.9850\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0390 Acc: 0.9878\n",
      "test Loss: 0.0400 Acc: 0.9883\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0368 Acc: 0.9884\n",
      "test Loss: 0.0420 Acc: 0.9858\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.0347 Acc: 0.9894\n",
      "test Loss: 0.0381 Acc: 0.9882\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0325 Acc: 0.9897\n",
      "test Loss: 0.0405 Acc: 0.9866\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.9903\n",
      "test Loss: 0.0432 Acc: 0.9857\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 0.9909\n",
      "test Loss: 0.0396 Acc: 0.9884\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0282 Acc: 0.9912\n",
      "test Loss: 0.0348 Acc: 0.9894\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9918\n",
      "test Loss: 0.0442 Acc: 0.9859\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0245 Acc: 0.9924\n",
      "test Loss: 0.0345 Acc: 0.9897\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.0238 Acc: 0.9925\n",
      "test Loss: 0.0346 Acc: 0.9888\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9930\n",
      "test Loss: 0.0417 Acc: 0.9869\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.9935\n",
      "test Loss: 0.0399 Acc: 0.9861\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9937\n",
      "test Loss: 0.0358 Acc: 0.9883\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0195 Acc: 0.9939\n",
      "test Loss: 0.0324 Acc: 0.9896\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0186 Acc: 0.9943\n",
      "test Loss: 0.0371 Acc: 0.9882\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0177 Acc: 0.9946\n",
      "test Loss: 0.0360 Acc: 0.9888\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.0167 Acc: 0.9950\n",
      "test Loss: 0.0378 Acc: 0.9881\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0156 Acc: 0.9953\n",
      "test Loss: 0.0365 Acc: 0.9891\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0152 Acc: 0.9952\n",
      "test Loss: 0.0352 Acc: 0.9877\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0140 Acc: 0.9961\n",
      "test Loss: 0.0352 Acc: 0.9888\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0138 Acc: 0.9957\n",
      "test Loss: 0.0369 Acc: 0.9884\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0131 Acc: 0.9958\n",
      "test Loss: 0.0357 Acc: 0.9887\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.0125 Acc: 0.9965\n",
      "test Loss: 0.0375 Acc: 0.9890\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.0119 Acc: 0.9966\n",
      "test Loss: 0.0391 Acc: 0.9880\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0114 Acc: 0.9967\n",
      "test Loss: 0.0376 Acc: 0.9890\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0111 Acc: 0.9967\n",
      "test Loss: 0.0377 Acc: 0.9891\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0098 Acc: 0.9973\n",
      "test Loss: 0.0380 Acc: 0.9888\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0097 Acc: 0.9973\n",
      "test Loss: 0.0363 Acc: 0.9889\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0088 Acc: 0.9976\n",
      "test Loss: 0.0384 Acc: 0.9889\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0085 Acc: 0.9979\n",
      "test Loss: 0.0356 Acc: 0.9897\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.0079 Acc: 0.9979\n",
      "test Loss: 0.0388 Acc: 0.9889\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0080 Acc: 0.9979\n",
      "test Loss: 0.0388 Acc: 0.9887\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0076 Acc: 0.9980\n",
      "test Loss: 0.0350 Acc: 0.9902\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0071 Acc: 0.9980\n",
      "test Loss: 0.0366 Acc: 0.9895\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0068 Acc: 0.9981\n",
      "test Loss: 0.0371 Acc: 0.9894\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0061 Acc: 0.9986\n",
      "test Loss: 0.0394 Acc: 0.9890\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0059 Acc: 0.9986\n",
      "test Loss: 0.0419 Acc: 0.9877\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.0056 Acc: 0.9986\n",
      "test Loss: 0.0376 Acc: 0.9891\n",
      "\n",
      "Training complete in 6m 52s\n",
      "Best val Acc: 0.990200\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = F.log_softmax(x, dim=1) # 计算log(softmax(x))\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_dataloader, test_dataloader, criterion, optimizer, num_epochs = 50):\n",
    "    since = time.time()\n",
    "  \n",
    "    best_acc = 0.0\n",
    "  \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch,num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        model.train() #Set model to training mode\n",
    "\n",
    "        train_running_loss = 0.0\n",
    "        train_running_corrects = 0\n",
    "\n",
    "        test_running_loss = 0.0\n",
    "        test_running_corrects = 0\n",
    "        \n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += loss.item() * inputs.size(0)\n",
    "            train_running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        train_epoch_loss = train_running_loss / len(train_dataloader.dataset)\n",
    "        train_epoch_acc = train_running_corrects.double() / len(train_dataloader.dataset)\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format('train', train_epoch_loss, train_epoch_acc))\n",
    "        writer.add_scalar('Train/Loss', train_epoch_loss, epoch)\n",
    "        writer.add_scalar('Train/Acc', train_epoch_acc, epoch)\n",
    "\n",
    "        model.eval()\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _,preds = torch.max(outputs,1)\n",
    "                loss = criterion(outputs,labels)\n",
    "\n",
    "                test_running_loss += loss.item() * inputs.size(0)\n",
    "                test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        test_epoch_loss = test_running_loss / len(test_dataloader.dataset)\n",
    "        test_epoch_acc = test_running_corrects.double() / len(test_dataloader.dataset)\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format('test', test_epoch_loss, test_epoch_acc))\n",
    "        writer.add_scalar('Test/Loss', test_epoch_loss, epoch)\n",
    "        writer.add_scalar('Test/Acc', test_epoch_acc, epoch)\n",
    "        if test_epoch_acc > best_acc:\n",
    "            best_acc = test_epoch_acc\n",
    "    \n",
    "    print()\n",
    "    writer.close() \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60 , time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    writer = SummaryWriter('./logs')\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307,), (0.3081,))])  # 标准化图像数据\n",
    "\n",
    "    trainset = datasets.MNIST(root='data', train=True,\n",
    "                                download=False, transform=transform)\n",
    "    train_loader = DataLoader(trainset, batch_size=64,\n",
    "                             shuffle=True)\n",
    "\n",
    "    testset = datasets.MNIST(root='data', train=False,\n",
    "                               download=False, transform=transform)\n",
    "    test_loader = DataLoader(testset, batch_size=32,\n",
    "                            shuffle=False)\n",
    "    lr = 0.001\n",
    "    epochs = 50\n",
    "    model = LeNet5().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(),lr=1e-3, momentum = 0.9)\n",
    "\n",
    "    model = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=epochs)\n",
    "\n",
    "    print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
